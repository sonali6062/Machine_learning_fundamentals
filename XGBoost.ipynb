{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonali6062/Machine_learning_fundamentals/blob/main/XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DVprzSRMHrAc"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for data manipulation, analysis, and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SWdqMeHIIYsw"
      },
      "outputs": [],
      "source": [
        "# Import machine learning libraries and functions\n",
        "import xgboost as xgb\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor # Corrected imports\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po4BqesOJ2lR"
      },
      "source": [
        "LOAD THE DATASET AND SPLIT INTO TRAIN\n",
        "AND TEST SETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y06Z0dp9JsPd"
      },
      "outputs": [],
      "source": [
        "# Load the California housing dataset\n",
        "california_housing=fetch_california_housing()\n",
        "x,y=california_housing.data,california_housing.target\n",
        "# Splitting the data into train and test set with a 80/20 split and a fixed random state\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZOIak1AKjxz",
        "outputId": "55bd4834-7577-478d-c864-e17bb69a376f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
              "           37.88      , -122.23      ],\n",
              "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
              "           37.86      , -122.22      ],\n",
              "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
              "           37.85      , -122.24      ],\n",
              "        ...,\n",
              "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
              "           39.43      , -121.22      ],\n",
              "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
              "           39.43      , -121.32      ],\n",
              "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
              "           39.37      , -121.24      ]]),\n",
              " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
              " 'frame': None,\n",
              " 'target_names': ['MedHouseVal'],\n",
              " 'feature_names': ['MedInc',\n",
              "  'HouseAge',\n",
              "  'AveRooms',\n",
              "  'AveBedrms',\n",
              "  'Population',\n",
              "  'AveOccup',\n",
              "  'Latitude',\n",
              "  'Longitude'],\n",
              " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 20640\\n\\n:Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n:Attribute Information:\\n    - MedInc        median income in block group\\n    - HouseAge      median house age in block group\\n    - AveRooms      average number of rooms per household\\n    - AveBedrms     average number of bedrooms per household\\n    - Population    block group population\\n    - AveOccup      average number of household members\\n    - Latitude      block group latitude\\n    - Longitude     block group longitude\\n\\n:Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. rubric:: References\\n\\n- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n  Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Display the loaded dataset object\n",
        "california_housing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQcq2zzUK_vh"
      },
      "source": [
        "DATA MODELLING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqJYtJNAQOzA"
      },
      "source": [
        "Initialising the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GoUSZD_WKrLI"
      },
      "outputs": [],
      "source": [
        "# Initialize the XGBoost, RandomForest, and GradientBoosting regressors with a fixed random state\n",
        "xgb_regressor=xgb.XGBRegressor(objective='reg:squarederror',random_state=42)\n",
        "rf_regressor=RandomForestRegressor(random_state=42)\n",
        "gb_regressor=GradientBoostingRegressor(random_state=42) # Corrected typo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7WVajDJQRa6"
      },
      "source": [
        "Data Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Mpj72gabQFbb"
      },
      "outputs": [],
      "source": [
        "# Train the initialized models on the training data\n",
        "model_xgb=xgb_regressor.fit(x_train,y_train)\n",
        "model_rf=rf_regressor.fit(x_train,y_train)\n",
        "model_gb=gb_regressor.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FCcadcDQ1mZ"
      },
      "source": [
        "Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RVAVmSqPQn94"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data using the trained models\n",
        "y_pred_xgb=model_xgb.predict(x_test)\n",
        "y_pred_rf=model_rf.predict(x_test)\n",
        "y_pred_gb=model_gb.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Oe-zp89RKtV"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ruBsKFRJqH",
        "outputId": "2167c021-2f3b-4824-afbb-55b70d840fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error for XGBoostRegressor:  0.2225899267544737\n",
            "Mean squared error for RandomForestRegressor:  0.2553684927247781\n",
            "Mean squared error for GradientBoostingRegressor:  0.2939973248643864\n"
          ]
        }
      ],
      "source": [
        "# Calculate the mean squared error for each model's predictions\n",
        "mse_xgb=mean_squared_error(y_test,y_pred_xgb)\n",
        "mse_rf=mean_squared_error(y_test,y_pred_rf)\n",
        "mse_gb=mean_squared_error(y_test,y_pred_gb)\n",
        "# Print the calculated mean squared errors\n",
        "print(\"Mean squared error for XGBoostRegressor: \",mse_xgb)\n",
        "print(\"Mean squared error for RandomForestRegressor: \",mse_rf)\n",
        "print(\"Mean squared error for GradientBoostingRegressor: \",mse_gb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gQbk3FVSQ9h"
      },
      "source": [
        "# Hyper Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ3uV3pPSjIa",
        "outputId": "5eea9f60-476c-458a-a2b7-a60e520c8366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning XGBoost...\n",
            "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
          ]
        }
      ],
      "source": [
        "# Define the hyperparameter grids for each model\n",
        "param_grid_xgb={\n",
        "    'lambda':[0.01,0.1,1,10],\n",
        "    'gamma':[0,0.1,1,10],\n",
        "    'learning_rate':[0.01,0.1,0.2],\n",
        "    'n_estimators':[100,200,300]\n",
        "}\n",
        "# param_grid_rf={\n",
        "#     'n_estimators':[100,200,300],\n",
        "#     'max_depth':[None,10,20,30],\n",
        "#     'min_samples_split':[2,5,10],\n",
        "#     'min_samples_leaf':[1,2,4]\n",
        "# }\n",
        "# param_grid_gb={\n",
        "#     'n_estimators':[100,200,300],\n",
        "#     'learning_rate':[0.01,0.1,0.2],\n",
        "#     'max_depth':[3,5,7],\n",
        "#     'min_samples_split':[2,5,10],\n",
        "#     'min_samples_leaf':[1,2,4]\n",
        "# }\n",
        "# Set up GridSearchCV for each model with 5-fold cross-validation and negative mean squared error as the scoring metric\n",
        "grid_search_xgb = GridSearchCV(estimator=xgb_regressor, param_grid=param_grid_xgb, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
        "# grid_search_rf = GridSearchCV(estimator=rf_regressor, param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
        "# grid_search_gb = GridSearchCV(estimator=gb_regressor, param_grid=param_grid_gb, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
        "# Fit the models to the training data to perform hyperparameter tuning\n",
        "print(\"Tuning XGBoost...\")\n",
        "grid_search_xgb.fit(x_train, y_train)\n",
        "# print(\"Tuning RandomForest...\")\n",
        "# grid_search_rf.fit(x_train, y_train)\n",
        "# print(\"Tuning GradientBoosting...\")\n",
        "# grid_search_gb.fit(x_train, y_train)\n",
        "\n",
        "# Get the best performing models after hyperparameter tuning\n",
        "best_xgb = grid_search_xgb.best_estimator_\n",
        "# best_rf = grid_search_rf.best_estimator_\n",
        "# best_gb = grid_search_gb.best_estimator_\n",
        "\n",
        "\n",
        "# Make predictions on the test data using the best models\n",
        "y_pred_xgb = best_xgb.predict(x_test)\n",
        "# y_pred_rf = best_rf.predict(x_test)\n",
        "# y_pred_gb = best_gb.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNLe7RLklzdu"
      },
      "source": [
        "Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3IapIiE_lw_h"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data using the initial models (before hyperparameter tuning)\n",
        "y_pred_xgb = model_xgb.predict(x_test)\n",
        "# y_pred_rf = model_rf.predict(x_test)\n",
        "# y_pred_gb = model_gb.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYllIcQCl5LK"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2y623wUBl80L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b97ab25-fbca-47ed-9dc1-363189f91abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for XGBRegressor:  {'gamma': 0, 'lambda': 10, 'learning_rate': 0.1, 'n_estimators': 300}\n",
            "Mean Squared Error for XGBRegressor:  0.2225899267544737\n"
          ]
        }
      ],
      "source": [
        "# Calculate Mean Squared Error for the predictions made by the initial models\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "# mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "# mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "\n",
        "# Print the best hyperparameters found for XGBoostRegressor and its corresponding Mean Squared Error\n",
        "print(\"Best parameters for XGBRegressor: \", grid_search_xgb.best_params_)\n",
        "print(\"Mean Squared Error for XGBRegressor: \", mse_xgb)\n",
        "\n",
        "# print(\"Best parameters for RandomForestRegressor: \", grid_search_rf.best_params_)\n",
        "# print(\"Mean Squared Error for RandomForestRegressor: \", mse_rf)\n",
        "\n",
        "# print(\"Best parameters for GradientBoostingRegressor: \", grid_search_gb.best_params_)\n",
        "# print(\"Mean Squared Error for GradientBoostingRegressor: \", mse_gb)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOHZ+57QQ5IDSQsgGJKl7Kh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}